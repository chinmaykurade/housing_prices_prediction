{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "#models:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,\\\n",
    "GradientBoostingRegressor, VotingRegressor, BaggingRegressor, ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBRegressor\n",
    "##\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the train and test datasets\n",
    "df_train = pd.read_csv(\"dataset/train_poly.csv\")\n",
    "df_test = pd.read_csv(\"dataset/test_poly.csv\")\n",
    "\n",
    "cols_train = df_train.columns.tolist()\n",
    "cols_test = df_test.columns.tolist()\n",
    "\n",
    "# Train the model with columns that exist both in train and test set\n",
    "cols_to_train = [col for col in cols_train if col in cols_test]\n",
    "cols_to_train.remove('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_i = df_train[cols_to_train]\n",
    "Y_train = df_train['SalePrice']\n",
    "X_test_i = df_test[cols_to_train]\n",
    "X_Id = df_test['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_i)\n",
    "X_test = scaler.transform(X_test_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training(+validation) set shape : (1448, 244)\n",
      "Y_train shape : (1448,)\n",
      "Test set shape : (1459, 244)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training(+validation) set shape : {}\".format(X_train.shape))\n",
    "print(\"Y_train shape : {}\".format(Y_train.shape))\n",
    "print(\"Test set shape : {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLA = [\n",
    "#     LinearRegression(),\n",
    "#     LogisticRegression(solver='sag',max_iter=300),\n",
    "#     GaussianNB(),\n",
    "# #     MLPRegressor(max_iter=1000,verbose=1),\n",
    "#     GradientBoostingRegressor(),\n",
    "# #     VotingRegressor(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)]),\n",
    "#     BaggingRegressor(),\n",
    "#     ExtraTreesRegressor(),\n",
    "#     DecisionTreeRegressor(),\n",
    "# #     SVC(probability=True),\n",
    "#     KNeighborsRegressor(n_neighbors = 4),\n",
    "#     RandomForestRegressor(n_estimators = 100),\n",
    "    XGBRegressor(learning_rate=0.01, n_estimators=3460,\n",
    "                max_depth=3, min_child_weight=0,\n",
    "                gamma=0, subsample=0.7,\n",
    "                colsample_bytree=0.7,\n",
    "                objective='reg:squarederror', nthread=-1,\n",
    "                scale_pos_weight=1, seed=27,\n",
    "                reg_alpha=0.00006)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBRegressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the classification on XGBRegressor\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train Error Mean</th>\n",
       "      <th>MLA Test Error Mean</th>\n",
       "      <th>MLA Test Error 3*STD</th>\n",
       "      <th>MLA Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>{'objective': 'reg:squarederror', 'base_score'...</td>\n",
       "      <td>-5750.52</td>\n",
       "      <td>-14051.8</td>\n",
       "      <td>1958.99</td>\n",
       "      <td>6.38973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MLA Name                                     MLA Parameters  \\\n",
       "0  XGBRegressor  {'objective': 'reg:squarederror', 'base_score'...   \n",
       "\n",
       "  MLA Train Error Mean MLA Test Error Mean MLA Test Error 3*STD MLA Time  \n",
       "0             -5750.52            -14051.8              1958.99  6.38973  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split dataset in cross-validation with this splitter class: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit\n",
    "#note: this is an alternative to train_test_split\n",
    "cv_split = ShuffleSplit(n_splits = 10, test_size = .20, train_size = .80, \\\n",
    "                                                random_state = 0 )\n",
    "                    # run model 10x with 60/30 split intentionally leaving out 10%\n",
    "\n",
    "#create table to compare MLA metrics\n",
    "MLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Error Mean', 'MLA Test Error Mean', \\\n",
    "               'MLA Test Error 3*STD' ,'MLA Time']\n",
    "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "\n",
    "#create table to compare MLA predictions\n",
    "MLA_predict = Y_train.copy()\n",
    "\n",
    "#index through MLA and save performance to table\n",
    "row_index = 0\n",
    "for alg in MLA:\n",
    "\n",
    "    #set name and parameters\n",
    "    MLA_name = alg.__class__.__name__\n",
    "    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
    "    MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
    "    \n",
    "    print(\"Running the classification on %s\" %(MLA_name))\n",
    "    \n",
    "    #score model with cross validation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n",
    "    cv_results = cross_validate(alg, X_train, Y_train, cv = cv_split,return_train_score=\\\n",
    "                                             True, scoring='neg_mean_absolute_error')\n",
    "\n",
    "    MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n",
    "    MLA_compare.loc[row_index, 'MLA Train Error Mean'] = cv_results['train_score'].mean()\n",
    "    MLA_compare.loc[row_index, 'MLA Test Error Mean'] = cv_results['test_score'].mean()   \n",
    "    #if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, \n",
    "    #should statistically capture 99.7% of the subsets\n",
    "    MLA_compare.loc[row_index, 'MLA Test Error 3*STD'] = cv_results['test_score'].std()*3   \n",
    "    #let's know the worst that can happen!\n",
    "    \n",
    "\n",
    "    #save MLA predictions - see section 6 for usage\n",
    "    alg.fit(X_train, Y_train)\n",
    "    MLA_predict[MLA_name] = alg.predict(X_train)\n",
    "    \n",
    "    row_index+=1\n",
    "\n",
    "    \n",
    "#print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\n",
    "MLA_compare.sort_values(by = ['MLA Test Error Mean'], ascending = False, inplace = True)\n",
    "MLA_compare\n",
    "#MLA_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLA[0]\n",
    "model.fit(X_train, Y_train)\n",
    "preds_train = model.predict(X_train)\n",
    "preds_test = model.predict(X_test)\n",
    "\n",
    "result = pd.DataFrame({\n",
    "    'Id':X_Id,\n",
    "    'SalePrice':preds_test\n",
    "})\n",
    "\n",
    "result.to_csv(\"dataset/result_xgb.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainn, X_valid, Y_trainn, Y_valid = train_test_split(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14784.280732044199\n"
     ]
    }
   ],
   "source": [
    "def get_mae_valid(model,X_train, X_valid, Y_train, Y_valid):\n",
    "    model.fit(X_train, Y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(Y_valid, preds)\n",
    "\n",
    "print(get_mae_valid(model,X_trainn, X_valid, Y_trainn, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "#     1. Polynomial features\n",
    "#     2. Grid Search\n",
    "#     3. Improve ordinal variables\n",
    "#     4. Feature Selection\n",
    "#     5. Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "GradientBoostingRegressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
