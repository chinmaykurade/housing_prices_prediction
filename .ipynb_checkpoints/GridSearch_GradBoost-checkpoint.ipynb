{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the train and test datasets\n",
    "df_train = pd.read_csv(\"dataset/train_final.csv\")\n",
    "df_test = pd.read_csv(\"dataset/test_final.csv\")\n",
    "\n",
    "cols_train = df_train.columns.tolist()\n",
    "cols_test = df_test.columns.tolist()\n",
    "\n",
    "# Train the model with columns that exist both in train and test set\n",
    "cols_to_train = [col for col in cols_train if col in cols_test]\n",
    "cols_to_train.remove('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_i = df_train[cols_to_train]\n",
    "Y_train = df_train['SalePrice']\n",
    "X_test_i = df_test[cols_to_train]\n",
    "X_Id = df_test['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_i)\n",
    "X_test = scaler.fit_transform(X_test_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training(+validation) set shape : (1460, 160)\n",
      "Y_train shape : (1460,)\n",
      "Test set shape : (1459, 160)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training(+validation) set shape : {}\".format(X_train.shape))\n",
    "print(\"Y_train shape : {}\".format(Y_train.shape))\n",
    "print(\"Test set shape : {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "#     'loss': ['deviance', 'exponential'], \n",
    "    'learning_rate': [.01,.05,.1,.2],\n",
    "    'n_estimators': [100,200,300,400,500],\n",
    "    'criterion': ['mae'], \n",
    "    'max_depth': [3,4,5],\n",
    "    'random_state': [0]\n",
    "}\n",
    "estmtr = GradientBoostingRegressor(verbose=1)\n",
    "cv_split = ShuffleSplit(n_splits = 10, test_size = .20, train_size = .80, random_state = 0 )\n",
    "best_model = GridSearchCV(estimator = estmtr, param_grid = param, cv = cv_split,\\\n",
    "                          scoring = 'neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1  6074408724.8968           21.03s\n",
      "         2  5993767577.8597           20.97s\n",
      "         3  5914356449.8165           20.70s\n",
      "         4  5836660640.9013           20.61s\n",
      "         5  5760741820.5130           20.58s\n",
      "         6  5686277123.2937           20.31s\n",
      "         7  5612987540.6256           20.03s\n",
      "         8  5540808633.5404           19.78s\n",
      "         9  5472421003.3700           19.55s\n",
      "        10  5401768904.4112           19.23s\n",
      "        20  4764632271.4536           16.92s\n",
      "        30  4230712316.6760           14.76s\n",
      "        40  3786845176.2714           12.71s\n",
      "        50  3401383745.4688           10.91s\n",
      "        60  3060093881.8060            8.82s\n",
      "        70  2766448149.4587            6.61s\n",
      "        80  2519454187.5761            4.41s\n",
      "        90  2306098255.0427            2.20s\n",
      "       100  2111759506.6892            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1  6089787103.4301           21.52s\n",
      "         2  6009750604.9997           21.11s\n",
      "         3  5935515946.1093           20.80s\n",
      "         4  5857983346.8967           20.54s\n",
      "         5  5787178974.2414           20.29s\n",
      "         6  5715274758.2293           20.08s\n",
      "         7  5642225722.3912           19.86s\n",
      "         8  5572908007.8240           19.67s\n",
      "         9  5506815683.0874           19.55s\n",
      "        10  5438368460.9766           19.35s\n",
      "        20  4835574787.2914           17.74s\n",
      "        30  4294162627.3251           16.12s\n",
      "        40  3818572408.0101           14.07s\n",
      "        50  3424826766.0311           11.58s\n",
      "        60  3105292877.2844            9.21s\n",
      "        70  2811343270.3013            6.87s\n",
      "        80  2537731177.6207            4.56s\n",
      "        90  2305032814.7124            2.28s\n",
      "       100  2095909629.4763            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1  5855363871.4239           22.41s\n",
      "         2  5775367109.5306           22.28s\n",
      "         3  5696944485.9804           21.77s\n",
      "         4  5620389281.7042           21.40s\n",
      "         5  5544983356.0549           21.17s\n",
      "         6  5471279343.1269           20.87s\n",
      "         7  5399001815.7572           20.56s\n",
      "         8  5327829685.8489           20.35s\n",
      "         9  5257706474.5672           20.20s\n",
      "        10  5191455779.3876           19.95s\n",
      "        20  4566919577.1811           17.29s\n",
      "        30  4040879777.9064           15.84s\n",
      "        40  3594909784.3165           13.62s\n",
      "        50  3212321689.6673           11.55s\n",
      "        60  2884856359.6956            9.20s\n",
      "        70  2598317172.1251            6.94s\n",
      "        80  2356315523.5890            4.61s\n",
      "        90  2140916383.0781            2.31s\n",
      "       100  1953356395.0255            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1  6101940644.0413           22.02s\n",
      "         2  6019926657.2796           22.19s\n",
      "         3  5939494300.7518           21.99s\n",
      "         4  5862215809.9691           21.40s\n",
      "         5  5784607136.1174           21.11s\n",
      "         6  5709842377.3604           21.12s\n",
      "         7  5635020322.3460           20.91s\n",
      "         8  5563750283.1849           20.54s\n",
      "         9  5491672540.8090           20.31s\n",
      "        10  5422949986.4390           20.18s\n",
      "        20  4796160185.4214           17.77s\n",
      "        30  4268744491.1707           15.53s\n",
      "        40  3820462849.4840           13.33s\n",
      "        50  3436203324.2245           11.04s\n",
      "        60  3106766568.0745            8.77s\n",
      "        70  2831720445.6482            6.58s\n",
      "        80  2574648083.9239            4.37s\n",
      "        90  2335087192.6145            2.18s\n",
      "       100  2126215405.5951            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1  6177295693.7381           25.67s\n",
      "         2  6097141259.4836           24.92s\n",
      "         3  6018513910.5105           23.48s\n",
      "         4  5941383937.7014           22.57s\n",
      "         5  5865722216.3513           21.94s\n",
      "         6  5791500194.6063           21.45s\n",
      "         7  5718689882.1307           21.19s\n",
      "         8  5647271380.2621           21.00s\n",
      "         9  5577201980.7790           20.64s\n",
      "        10  5506569732.4320           20.38s\n",
      "        20  4874090241.0610           17.95s\n",
      "        30  4349078071.1575           15.46s\n",
      "        40  3881181198.9474           13.41s\n",
      "        50  3459461859.2648           11.41s\n",
      "        60  3095146244.7563            9.05s\n",
      "        70  2773321835.5177            6.87s\n",
      "        80  2515499066.6820            4.60s\n",
      "        90  2290892334.5529            2.32s\n",
      "       100  2101937051.5248            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1  5885848951.5062           25.57s\n",
      "         2  5805974224.3042           25.02s\n",
      "         3  5727650208.7716           24.80s\n",
      "         4  5650104786.3330           24.66s\n",
      "         5  5573609857.3600           24.29s\n",
      "         6  5498832848.7464           23.39s\n",
      "         7  5425672345.9650           22.71s\n",
      "         8  5353295974.6631           22.11s\n",
      "         9  5282453796.7780           21.64s\n",
      "        10  5213036049.1680           21.19s\n",
      "        20  4600060814.1202           18.85s\n",
      "        30  4077160058.6056           16.34s\n",
      "        40  3626479803.4712           13.72s\n",
      "        50  3242611324.4254           11.34s\n",
      "        60  2919154821.0493            9.16s\n",
      "        70  2634040835.1218            6.92s\n",
      "        80  2384523777.7096            4.65s\n",
      "        90  2174489224.8153            2.34s\n",
      "       100  1992942707.4419            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1  6282192331.3616           27.74s\n",
      "         2  6197736552.1444           26.97s\n",
      "         3  6115071823.2952           25.57s\n",
      "         4  6034465246.2747           24.77s\n",
      "         5  5955494778.0818           23.93s\n",
      "         6  5877406159.8580           23.08s\n",
      "         7  5800781912.1447           22.49s\n",
      "         8  5726724484.0423           22.02s\n",
      "         9  5653314540.4140           21.64s\n",
      "        10  5581977081.6136           21.35s\n",
      "        20  4935681626.5644           19.69s\n",
      "        30  4381920124.4627           16.51s\n",
      "        40  3908012816.5410           13.78s\n",
      "        50  3513063554.8036           11.34s\n",
      "        60  3171896989.4965            9.03s\n",
      "        70  2890014867.7304            6.76s\n",
      "        80  2622756033.3599            4.50s\n",
      "        90  2389911592.3841            2.25s\n",
      "       100  2187239282.0834            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1  6370528869.0399           21.03s\n",
      "         2  6287517293.3511           21.16s\n",
      "         3  6209225340.7330           20.87s\n",
      "         4  6128734652.4010           20.51s\n",
      "         5  6050244450.6247           20.28s\n",
      "         6  5975967587.0797           20.16s\n",
      "         7  5899900184.5206           20.05s\n",
      "         8  5828831155.1692           19.89s\n",
      "         9  5756504632.2951           19.66s\n",
      "        10  5687936286.4009           19.46s\n",
      "        20  5057496959.7367           18.55s\n",
      "        30  4519498867.0119           16.11s\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param = best_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators = 100)\n",
    "model.fit(X_train, Y_train)\n",
    "preds_train = model.predict(X_train)\n",
    "preds_test = model.predict(X_test)\n",
    "\n",
    "result = pd.DataFrame({\n",
    "    'Id':X_Id,\n",
    "    'SalePrice':preds_test\n",
    "})\n",
    "\n",
    "result.to_csv(\"dataset/result_rf.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainn, X_valid, Y_trainn, Y_valid = train_test_split(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16572.04104109589\n"
     ]
    }
   ],
   "source": [
    "def get_mae_valid(model,X_train, X_valid, Y_train, Y_valid):\n",
    "    model.fit(X_train, Y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(Y_valid, preds)\n",
    "\n",
    "print(get_mae_valid(model,X_trainn, X_valid, Y_trainn, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "#     1. Polynomial features\n",
    "#     2. Grid Search\n",
    "#     3. Improve ordinal variables\n",
    "#     4. Feature Selection\n",
    "#     5. Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
