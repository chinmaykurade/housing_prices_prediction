{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the train and test datasets\n",
    "df_train = pd.read_csv(\"dataset/train_final.csv\")\n",
    "df_test = pd.read_csv(\"dataset/test_final.csv\")\n",
    "\n",
    "cols_train = df_train.columns.tolist()\n",
    "cols_test = df_test.columns.tolist()\n",
    "\n",
    "# Train the model with columns that exist both in train and test set\n",
    "cols_to_train = [col for col in cols_train if col in cols_test]\n",
    "cols_to_train.remove('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_i = df_train[cols_to_train]\n",
    "Y_train = df_train['SalePrice']\n",
    "X_test_i = df_test[cols_to_train]\n",
    "X_Id = df_test['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_i)\n",
    "X_test = scaler.transform(X_test_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training(+validation) set shape : (1448, 184)\n",
      "Y_train shape : (1448,)\n",
      "Test set shape : (1459, 184)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training(+validation) set shape : {}\".format(X_train.shape))\n",
    "print(\"Y_train shape : {}\".format(Y_train.shape))\n",
    "print(\"Test set shape : {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "#     'loss': ['deviance', 'exponential'], \n",
    "    'learning_rate': [.01],\n",
    "    'n_estimators': [5000,5005,5010],\n",
    "#     'criterion': ['mae'], \n",
    "    'max_depth': [3],\n",
    "#     'random_state': [0],\n",
    "    'min_child_weight':[0],\n",
    "    'gamma':[0],\n",
    "    'subsample':[0.7],\n",
    "    'colsample_bytree':[0.7],\n",
    "    'objective':['reg:squarederror'], \n",
    "    'nthread':[-1],\n",
    "    'scale_pos_weight':[1],\n",
    "    'seed':[27],\n",
    "    'reg_alpha':[0.00006]\n",
    "}\n",
    "estmtr = XGBRegressor()\n",
    "cv_split = ShuffleSplit(n_splits = 5, test_size = .20, train_size = .80, random_state = 0 )\n",
    "best_model = GridSearchCV(estimator = estmtr, param_grid = param, cv = cv_split,\\\n",
    "                          scoring = 'neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=5, random_state=0, test_size=0.2, train_size=0.8),\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, gamma=None,\n",
       "                                    gpu_id=None, importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_delta_step=None,\n",
       "                                    max_depth=None, min_child_weight=...\n",
       "                                    tree_method=None, validate_parameters=None,\n",
       "                                    verbosity=None),\n",
       "             param_grid={'colsample_bytree': [0.7], 'gamma': [0],\n",
       "                         'learning_rate': [0.01], 'max_depth': [3],\n",
       "                         'min_child_weight': [0],\n",
       "                         'n_estimators': [5000, 5005, 5010], 'nthread': [-1],\n",
       "                         'objective': ['reg:squarederror'],\n",
       "                         'reg_alpha': [6e-05], 'scale_pos_weight': [1],\n",
       "                         'seed': [27], 'subsample': [0.7]},\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are : {'colsample_bytree': 0.7, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 0, 'n_estimators': 5000, 'nthread': -1, 'objective': 'reg:squarederror', 'reg_alpha': 6e-05, 'scale_pos_weight': 1, 'seed': 27, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "best_param = best_model.best_params_\n",
    "print(\"Best parameters are : {}\".format(best_param))\n",
    "estmtr.set_params(**best_param)\n",
    "estmtr.fit(X_train, Y_train)\n",
    "preds_train = estmtr.predict(X_train)\n",
    "preds_test = estmtr.predict(X_test)\n",
    "\n",
    "result = pd.DataFrame({\n",
    "    'Id':X_Id,\n",
    "    'SalePrice':preds_test\n",
    "})\n",
    "\n",
    "result.to_csv(\"dataset/result_xgb_CV.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "#     1. Polynomial features\n",
    "#     2. Grid Search\n",
    "#     3. Improve ordinal variables\n",
    "#     4. Feature Selection\n",
    "#     5. Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
