{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "#models:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,\\\n",
    "GradientBoostingRegressor, VotingRegressor, BaggingRegressor, ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVC\n",
    "##\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the train and test datasets\n",
    "df_train = pd.read_csv(\"dataset/train_final.csv\")\n",
    "df_test = pd.read_csv(\"dataset/test_final.csv\")\n",
    "\n",
    "cols_train = df_train.columns.tolist()\n",
    "cols_test = df_test.columns.tolist()\n",
    "\n",
    "# Train the model with columns that exist both in train and test set\n",
    "cols_to_train = [col for col in cols_train if col in cols_test]\n",
    "cols_to_train.remove('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_i = df_train[cols_to_train]\n",
    "Y_train = df_train['SalePrice']\n",
    "X_test_i = df_test[cols_to_train]\n",
    "X_Id = df_test['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_i)\n",
    "X_test = scaler.fit_transform(X_test_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training(+validation) set shape : (1460, 160)\n",
      "Y_train shape : (1460,)\n",
      "Test set shape : (1459, 160)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training(+validation) set shape : {}\".format(X_train.shape))\n",
    "print(\"Y_train shape : {}\".format(Y_train.shape))\n",
    "print(\"Test set shape : {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLA = [\n",
    "    LinearRegression(),\n",
    "    LogisticRegression(solver='sag',max_iter=300),\n",
    "    GaussianNB(),\n",
    "#     MLPRegressor(max_iter=1000,verbose=1),\n",
    "    GradientBoostingRegressor(),\n",
    "#     VotingRegressor(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)]),\n",
    "    BaggingRegressor(),\n",
    "    ExtraTreesRegressor(),\n",
    "    DecisionTreeRegressor(),\n",
    "#     SVC(probability=True),\n",
    "    KNeighborsRegressor(n_neighbors = 4),\n",
    "    RandomForestRegressor(n_estimators = 100)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the classification on LinearRegression\n",
      "{'fit_time': array([0.01097035, 0.00897479, 0.00797987, 0.00897694, 0.0079782 ,\n",
      "       0.00797749, 0.00997114, 0.01196909, 0.01296329, 0.01296592]), 'score_time': array([0.00099826, 0.00099826, 0.00099707, 0.0009973 , 0.00099683,\n",
      "       0.00099754, 0.        , 0.        , 0.00099802, 0.00099993]), 'test_score': array([-8.61847856e+13, -2.18221548e+04, -2.33768255e+04, -4.92749520e+13,\n",
      "       -2.06098144e+04, -2.19351161e+04, -2.27909121e+04, -1.39296591e+14,\n",
      "       -2.02047065e+04, -1.11932944e+13]), 'train_score': array([-15274.84837864, -17385.16670576, -15312.38789964, -15904.54728636,\n",
      "       -16288.71634213, -16892.93276407, -16646.92582743, -16995.36856539,\n",
      "       -16001.00502997, -17771.3098897 ])}\n",
      "Running the classification on LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([ 95.93451691,  97.30186224,  94.15225458, 101.05682349,\n",
      "       100.54619074,  93.19985533,  96.25066757,  98.38396788,\n",
      "        95.47180581,  99.74944234]), 'score_time': array([0.00299072, 0.00398874, 0.0029912 , 0.00399351, 0.0039866 ,\n",
      "       0.00196743, 0.00199723, 0.0029912 , 0.0029397 , 0.00295162]), 'test_score': array([-37427.00684932, -35948.49657534, -33200.3390411 , -35461.03424658,\n",
      "       -33283.60273973, -36594.01369863, -34512.54794521, -34966.42808219,\n",
      "       -33645.8390411 , -35097.64041096]), 'train_score': array([ -80.05136986,  -37.67123288,  -20.11986301,  -95.03424658,\n",
      "        -83.98972603, -131.93493151, -117.80821918,  -41.5239726 ,\n",
      "       -150.34246575, -123.37328767])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the classification on GaussianNB\n",
      "{'fit_time': array([0.03690124, 0.0359478 , 0.03691053, 0.03195357, 0.0309546 ,\n",
      "       0.02992535, 0.03490663, 0.02992034, 0.03092384, 0.03391838]), 'score_time': array([0.11170459, 0.10667133, 0.10175896, 0.09570765, 0.08972287,\n",
      "       0.08776665, 0.08975863, 0.08781481, 0.09070492, 0.10167885]), 'test_score': array([-41539.9109589 , -41873.15068493, -40002.26369863, -41550.62671233,\n",
      "       -43314.26712329, -42385.71917808, -39219.47945205, -37619.25342466,\n",
      "       -37468.32191781, -35620.18150685]), 'train_score': array([-4073.97260274, -3383.90410959, -4144.43493151, -4047.60273973,\n",
      "       -4353.16780822, -4487.32876712, -3874.82876712, -3873.8869863 ,\n",
      "       -4671.40410959, -4365.06849315])}\n",
      "Running the classification on GradientBoostingRegressor\n",
      "{'fit_time': array([0.72506642, 0.70809221, 0.72110415, 0.72505021, 0.73902297,\n",
      "       0.69810724, 0.70615149, 0.70412803, 0.70810676, 0.70516443]), 'score_time': array([0.00197792, 0.00099683, 0.00099421, 0.00099659, 0.0009706 ,\n",
      "       0.00299072, 0.00195599, 0.0009973 , 0.00099802, 0.00099468]), 'test_score': array([-16807.58415393, -17295.59216983, -18045.04947782, -16126.86445353,\n",
      "       -16114.0380461 , -17888.36347524, -15606.4756351 , -16693.87557213,\n",
      "       -15146.86156065, -15416.44579255]), 'train_score': array([-10064.53743781,  -9896.90975623,  -9896.65608549, -10205.45844094,\n",
      "       -10430.68682072,  -9812.84773575, -10068.73041581, -10292.25279758,\n",
      "       -10254.75679273, -10523.02750774])}\n",
      "Running the classification on BaggingRegressor\n",
      "{'fit_time': array([0.24534082, 0.24434161, 0.24431181, 0.25033259, 0.24933267,\n",
      "       0.24833512, 0.24334884, 0.24338341, 0.24135423, 0.24737763]), 'score_time': array([0.00499034, 0.00398922, 0.00403094, 0.00398993, 0.00399017,\n",
      "       0.00398993, 0.00398946, 0.00399184, 0.00303459, 0.00399351]), 'test_score': array([-19053.54349315, -18641.8609589 , -19757.95787671, -18911.61472603,\n",
      "       -21056.39657534, -21753.28561644, -18195.2890411 , -19168.78424658,\n",
      "       -18636.92636986, -18082.42876712]), 'train_score': array([-7723.5067637 , -7743.04726027, -7720.03570205, -7448.06909247,\n",
      "       -7633.52756849, -7345.33304795, -7795.62696918, -7782.70710616,\n",
      "       -8038.38544521, -8155.24178082])}\n",
      "Running the classification on ExtraTreesRegressor\n",
      "{'fit_time': array([1.90096235, 2.37170267, 2.00459433, 2.07550001, 1.88595772,\n",
      "       1.94480538, 1.9567697 , 2.02961349, 1.94184923, 1.88195348]), 'score_time': array([0.01296949, 0.0139668 , 0.01299214, 0.01296353, 0.01296568,\n",
      "       0.01201296, 0.0140121 , 0.01292729, 0.01296544, 0.01097035]), 'test_score': array([-17293.88969178, -18118.79986301, -18078.96527397, -17685.61441781,\n",
      "       -17421.00027397, -19083.6455137 , -16386.88260274, -16664.3484589 ,\n",
      "       -15721.71246575, -16107.65664384]), 'train_score': array([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0.])}\n",
      "Running the classification on DecisionTreeRegressor\n",
      "{'fit_time': array([0.03585982, 0.03490901, 0.0418601 , 0.03993177, 0.03889561,\n",
      "       0.04288435, 0.04185939, 0.04089069, 0.03889537, 0.04289627]), 'score_time': array([0.00099778, 0.00100064, 0.0009973 , 0.00095916, 0.00099707,\n",
      "       0.00199866, 0.00102401, 0.        , 0.00103664, 0.        ]), 'test_score': array([-27582.28424658, -25721.51027397, -25936.07534247, -26201.3869863 ,\n",
      "       -27560.64041096, -27249.9760274 , -27304.52054795, -26356.29452055,\n",
      "       -25642.34589041, -25512.60616438]), 'train_score': array([-0., -0., -0., -0., -0., -0., -0., -0., -0., -0.])}\n",
      "Running the classification on KNeighborsRegressor\n",
      "{'fit_time': array([0.03892469, 0.03395438, 0.03293824, 0.03093266, 0.03189993,\n",
      "       0.0319128 , 0.03191495, 0.03786182, 0.0339458 , 0.03191376]), 'score_time': array([0.11066103, 0.09573841, 0.09375072, 0.0927527 , 0.08976769,\n",
      "       0.09173346, 0.08975935, 0.10474229, 0.10373759, 0.09480071]), 'test_score': array([-28959.78167808, -26000.15068493, -29554.62243151, -30290.37328767,\n",
      "       -27000.07277397, -29024.13441781, -27675.66181507, -25664.79452055,\n",
      "       -27070.13441781, -25164.93578767]), 'train_score': array([-19778.40625   , -21087.49978596, -19902.17422945, -19997.91031678,\n",
      "       -21200.61087329, -20307.99250856, -20434.23309075, -21260.58989726,\n",
      "       -20649.00770548, -21401.78574486])}\n",
      "Running the classification on RandomForestRegressor\n",
      "{'fit_time': array([1.94484591, 1.90795016, 1.87802148, 1.9019165 , 1.94978905,\n",
      "       2.13329601, 1.95381665, 2.07342887, 2.23206019, 1.9657867 ]), 'score_time': array([0.01292133, 0.00995541, 0.00995874, 0.01296473, 0.01196551,\n",
      "       0.01396251, 0.00997233, 0.01296616, 0.01194143, 0.01197457]), 'test_score': array([-17219.20976027, -18211.62061644, -18645.34996575, -18812.8709589 ,\n",
      "       -18777.01688356, -19605.11876712, -16796.0634589 , -17907.39503425,\n",
      "       -17729.86712329, -16174.63914384]), 'train_score': array([-6602.43119007, -6341.49093322, -6634.18351884, -6665.01748288,\n",
      "       -6811.05097603, -6416.47291096, -6679.2565411 , -6779.27798801,\n",
      "       -6821.21571062, -6729.92324486])}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLA Name</th>\n",
       "      <th>MLA Parameters</th>\n",
       "      <th>MLA Train Error Mean</th>\n",
       "      <th>MLA Test Error Mean</th>\n",
       "      <th>MLA Test Error 3*STD</th>\n",
       "      <th>MLA Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>{'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': ...</td>\n",
       "      <td>-10144.6</td>\n",
       "      <td>-16514.1</td>\n",
       "      <td>2872.73</td>\n",
       "      <td>0.713999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'criter...</td>\n",
       "      <td>0</td>\n",
       "      <td>-17256.3</td>\n",
       "      <td>2962.77</td>\n",
       "      <td>1.99937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...</td>\n",
       "      <td>-6648.03</td>\n",
       "      <td>-17987.9</td>\n",
       "      <td>2965.8</td>\n",
       "      <td>1.99409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
       "      <td>-7738.55</td>\n",
       "      <td>-19325.8</td>\n",
       "      <td>3435.11</td>\n",
       "      <td>0.245746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>{'ccp_alpha': 0.0, 'criterion': 'mse', 'max_de...</td>\n",
       "      <td>0</td>\n",
       "      <td>-26506.8</td>\n",
       "      <td>2371.7</td>\n",
       "      <td>0.0398882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "      <td>-20602</td>\n",
       "      <td>-27640.5</td>\n",
       "      <td>5001.99</td>\n",
       "      <td>0.0336199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
       "      <td>-88.1849</td>\n",
       "      <td>-35013.7</td>\n",
       "      <td>4003.44</td>\n",
       "      <td>97.2047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>{'priors': None, 'var_smoothing': 1e-09}</td>\n",
       "      <td>-4127.56</td>\n",
       "      <td>-40059.3</td>\n",
       "      <td>7149.49</td>\n",
       "      <td>0.0332262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>{'copy_X': True, 'fit_intercept': True, 'n_job...</td>\n",
       "      <td>-16447.3</td>\n",
       "      <td>-2.8595e+13</td>\n",
       "      <td>1.38156e+14</td>\n",
       "      <td>0.0100727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    MLA Name  \\\n",
       "3  GradientBoostingRegressor   \n",
       "5        ExtraTreesRegressor   \n",
       "8      RandomForestRegressor   \n",
       "4           BaggingRegressor   \n",
       "6      DecisionTreeRegressor   \n",
       "7        KNeighborsRegressor   \n",
       "1         LogisticRegression   \n",
       "2                 GaussianNB   \n",
       "0           LinearRegression   \n",
       "\n",
       "                                      MLA Parameters MLA Train Error Mean  \\\n",
       "3  {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': ...             -10144.6   \n",
       "5  {'bootstrap': False, 'ccp_alpha': 0.0, 'criter...                    0   \n",
       "8  {'bootstrap': True, 'ccp_alpha': 0.0, 'criteri...             -6648.03   \n",
       "4  {'base_estimator': None, 'bootstrap': True, 'b...             -7738.55   \n",
       "6  {'ccp_alpha': 0.0, 'criterion': 'mse', 'max_de...                    0   \n",
       "7  {'algorithm': 'auto', 'leaf_size': 30, 'metric...               -20602   \n",
       "1  {'C': 1.0, 'class_weight': None, 'dual': False...             -88.1849   \n",
       "2           {'priors': None, 'var_smoothing': 1e-09}             -4127.56   \n",
       "0  {'copy_X': True, 'fit_intercept': True, 'n_job...             -16447.3   \n",
       "\n",
       "  MLA Test Error Mean MLA Test Error 3*STD   MLA Time  \n",
       "3            -16514.1              2872.73   0.713999  \n",
       "5            -17256.3              2962.77    1.99937  \n",
       "8            -17987.9               2965.8    1.99409  \n",
       "4            -19325.8              3435.11   0.245746  \n",
       "6            -26506.8               2371.7  0.0398882  \n",
       "7            -27640.5              5001.99  0.0336199  \n",
       "1            -35013.7              4003.44    97.2047  \n",
       "2            -40059.3              7149.49  0.0332262  \n",
       "0         -2.8595e+13          1.38156e+14  0.0100727  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split dataset in cross-validation with this splitter class: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit\n",
    "#note: this is an alternative to train_test_split\n",
    "cv_split = ShuffleSplit(n_splits = 10, test_size = .20, train_size = .80, \\\n",
    "                                                random_state = 0 )\n",
    "                    # run model 10x with 60/30 split intentionally leaving out 10%\n",
    "\n",
    "#create table to compare MLA metrics\n",
    "MLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Error Mean', 'MLA Test Error Mean', \\\n",
    "               'MLA Test Error 3*STD' ,'MLA Time']\n",
    "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "\n",
    "#create table to compare MLA predictions\n",
    "MLA_predict = Y_train.copy()\n",
    "\n",
    "#index through MLA and save performance to table\n",
    "row_index = 0\n",
    "for alg in MLA:\n",
    "\n",
    "    #set name and parameters\n",
    "    MLA_name = alg.__class__.__name__\n",
    "    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
    "    MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
    "    \n",
    "    print(\"Running the classification on %s\" %(MLA_name))\n",
    "    \n",
    "    #score model with cross validation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n",
    "    cv_results = cv_results = cross_validate(alg, X_train, Y_train, cv = cv_split,return_train_score=\\\n",
    "                                             True, scoring='neg_mean_absolute_error')\n",
    "\n",
    "    MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n",
    "    MLA_compare.loc[row_index, 'MLA Train Error Mean'] = cv_results['train_score'].mean()\n",
    "    MLA_compare.loc[row_index, 'MLA Test Error Mean'] = cv_results['test_score'].mean()   \n",
    "    #if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, \n",
    "    #should statistically capture 99.7% of the subsets\n",
    "    MLA_compare.loc[row_index, 'MLA Test Error 3*STD'] = cv_results['test_score'].std()*3   \n",
    "    #let's know the worst that can happen!\n",
    "    \n",
    "\n",
    "    #save MLA predictions - see section 6 for usage\n",
    "    alg.fit(X_train, Y_train)\n",
    "    MLA_predict[MLA_name] = alg.predict(X_train)\n",
    "    \n",
    "    row_index+=1\n",
    "\n",
    "    \n",
    "#print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\n",
    "MLA_compare.sort_values(by = ['MLA Test Error Mean'], ascending = False, inplace = True)\n",
    "MLA_compare\n",
    "#MLA_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor(n_estimators=400)\n",
    "model.fit(X_train, Y_train)\n",
    "preds_train = model.predict(X_train)\n",
    "preds_test = model.predict(X_test)\n",
    "\n",
    "result = pd.DataFrame({\n",
    "    'Id':X_Id,\n",
    "    'SalePrice':preds_test\n",
    "})\n",
    "\n",
    "result.to_csv(\"dataset/result_gb.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainn, X_valid, Y_trainn, Y_valid = train_test_split(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15653.447190680452\n"
     ]
    }
   ],
   "source": [
    "def get_mae_valid(model,X_train, X_valid, Y_train, Y_valid):\n",
    "    model.fit(X_train, Y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(Y_valid, preds)\n",
    "\n",
    "print(get_mae_valid(model,X_trainn, X_valid, Y_trainn, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "#     1. Polynomial features\n",
    "#     2. Grid Search\n",
    "#     3. Improve ordinal variables\n",
    "#     4. Feature Selection\n",
    "#     5. Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "GradientBoostingRegressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
